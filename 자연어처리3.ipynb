{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "자연어처리3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP38cwqfekwUjhm9eut5hD0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonDongBin/python-file/blob/master/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3cCSz-S6okz"
      },
      "outputs": [],
      "source": [
        "doc1 = '정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다'\n",
        "vocab, bow = build_bag_of_word(doc1)\n",
        "print('vocabulary :', vocab)\n",
        "print('bag of word vector :', bow)\n",
        "doc2 = '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다'\n",
        "vocab, bow = build_bag_of_word(doc2)\n",
        "print('vocabulary :', vocab)\n",
        "print('bag of word vector :', bow)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from math import log\n",
        "docs = [\n",
        "        '먹고 싶은 사과',\n",
        "        '먹고 싶은 바나나',\n",
        "        '길고 노란 바나나 바나나',\n",
        "        '저는 과일이 좋아요'\n",
        "]\n",
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "vocab.sort()"
      ],
      "metadata": {
        "id": "E9QU_m6c-c4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(docs)\n",
        "def tf(t,d):\n",
        "  return d.count(t)\n",
        "def idf(t):\n",
        "  df = 0\n",
        "  for doc in docs:\n",
        "    df += t in doc\n",
        "  return log(N(df+1))\n",
        "def tfdf(t,d):\n",
        "  return tf(t,d)*idf(t)"
      ],
      "metadata": {
        "id": "rYqoSjzP_gVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for i in range(N):\n",
        "  result.append([])\n",
        "  d = docs[i]\n",
        "  for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "    result[-1].append(tf(t,d))\n",
        "  tf_ = pd.DataFrame(result, columns = vocab)"
      ],
      "metadata": {
        "id": "clNxGYiMAKiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "    result.append(idf(t))\n",
        "\n",
        "idf_ = pd.DataFrame(result, index=vocab, columns=[\"IDF\"])\n",
        "idf_"
      ],
      "metadata": {
        "id": "EUFEuvX-Co78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for i in range(N):\n",
        "  result.append([])\n",
        "  d = docs[i]\n",
        "  for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "    result[-1].append(tfidf(t,d))\n",
        "\n",
        "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
        "tfidf_"
      ],
      "metadata": {
        "id": "1ibM6VGoLACp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = [\n",
        "          'you know I want your love',\n",
        "          'I like you',\n",
        "          'what should I do'\n",
        "]\n",
        "tfidfv = Tfidfvectorizer()\n",
        "# 코처스로부터 각 단어의 빈도수를 기록\n",
        "print(tfidfv.fit_transform(corpus).toarray())\n",
        "# 각 단어와 맵핑된 인덱스 출력\n",
        "print(tfidfv.vocabulary_)"
      ],
      "metadata": {
        "id": "wrR9sY8MDF_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfv = TfidfVectorizer().fit(corpus)\n",
        "print(tfidfv.transform(corpus).toarray())\n",
        "print(tfidfv.vocabulary_)"
      ],
      "metadata": {
        "id": "yQKyBfAMLNQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(A, B):\n",
        "  return dot(A, B)/(norm(A)*norm(B))\n",
        "\n",
        "doc1 = np.array([0,1,1,1])\n",
        "doc2 = np.array([1,0,1,1])\n",
        "doc3 = np.array([2,0,2,2])\n",
        "\n",
        "print('문서 1과 문서2의 유사도 :',cos_sim(doc1, doc2))\n",
        "print('문서 1과 문서3의 유사도 :',cos_sim(doc1, doc3))\n",
        "print('문서 2와 문서3의 유사도 :',cos_sim(doc2, doc3))"
      ],
      "metadata": {
        "id": "N6Sc4qCSKxhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "data = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
        "data.head(2)\n",
        "# 상위 2만개의 샘플을 data에 저장\n",
        "data = data.head(20000)\n",
        "# overview 열에 존재하는 모든 결측값을 전부 카운트하여 출력\n",
        "print('overview 열의 결측값의 수:',data['overview'].isnull().sum())"
      ],
      "metadata": {
        "id": "mqL7t3HILRl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측값을 빈 값으로 대체\n",
        "data['overview'] = data['overview'].fillna('')\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(data['overview'])\n",
        "print('TF-IDF 행렬의 크기(shape) :',tfidf_matrix.shape)"
      ],
      "metadata": {
        "id": "sH5rEfktU7va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "print('코사인 유사도 연산 결과 :',cosine_sim.shape)"
      ],
      "metadata": {
        "id": "mIMa_3dPVxtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_to_index = dict(zip(data['title'], data.index))\n",
        "\n",
        "# 영화 제목 Father of the Bride Part II의 인덱스를 리턴\n",
        "idx = title_to_index['Father of the Bride Part II']\n",
        "print(idx)"
      ],
      "metadata": {
        "id": "cT4-2MheW6C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(title, cosine_sim=cosine_sim):\n",
        "    # 선택한 영화의 타이틀로부터 해당 영화의 인덱스를 받아온다.\n",
        "    idx = title_to_index[title]\n",
        "\n",
        "    # 해당 영화와 모든 영화와의 유사도를 가져온다.\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # 유사도에 따라 영화들을 정렬한다.\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # 가장 유사한 10개의 영화를 받아온다.\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # 가장 유사한 10개의 영화의 인덱스를 얻는다.\n",
        "    movie_indices = [idx[0] for idx in sim_scores]\n",
        "\n",
        "    # 가장 유사한 10개의 영화의 제목을 리턴한다.\n",
        "    return data['title'].iloc[movie_indices]\n",
        "\n",
        "    get_recommendations('The Dark Knight Rises')"
      ],
      "metadata": {
        "id": "rTILQU9KW9tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = \"apple banana everyone like likey watch card holder\"\n",
        "doc2 = \"apple banana coupon passport love you\"\n",
        "\n",
        "# 토큰화\n",
        "tokenized_doc1 = doc1.split()\n",
        "tokenized_doc2 = doc2.split()\n",
        "\n",
        "print('문서1 :',tokenized_doc1)\n",
        "print('문서2 :',tokenized_doc2)"
      ],
      "metadata": {
        "id": "TlIJWlX2hVse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "union = set(tokenized_doc1)|(set(tokenized_doc2))\n",
        "intersection = set(tokenized_doc1)&(set(tokenized_doc2))\n",
        "print('자카드 유사도 :',len(intersection)/len(union))"
      ],
      "metadata": {
        "id": "l9cUTbR1hXV-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}