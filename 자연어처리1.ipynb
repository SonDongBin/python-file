{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "자연어처리1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHiSvkboJjWDISRe40at0G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonDongBin/python-file/blob/master/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = \"A barber is a person. a barber is good person. \\\n",
        "  a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. \\\n",
        "  Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. \\\n",
        "  But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
      ],
      "metadata": {
        "id": "Tot4krv8vmYy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wse3ObhQuR2w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "de326800-56e5-400b-bf83-7e52bae66f88"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-617cbce58eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpreprocessed_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# 단어 토큰화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stopword' is not defined"
          ]
        }
      ],
      "source": [
        "vocab = {}\n",
        "preprocessed_sentences = []\n",
        "stop_words = set(stopword.words('english'))\n",
        "for sentence in sentences:\n",
        "  # 단어 토큰화\n",
        "  tokenized_sentence = word_tokenize(sentence)\n",
        "  result = []\n",
        "\n",
        "  for word in tokenized_sentence:\n",
        "    word = word.lower()\n",
        "    if word not in stop_words:\n",
        "      if len(word) > 2:\n",
        "        result.append(word)\n",
        "        if word not in vocab:\n",
        "          vocab[word] = 0\n",
        "\n",
        "        vocab[word] += 1\n",
        "      preprocessed_sentences.append(result)\n",
        "    print(preprocessed_sentences)\n",
        "    print(vocab)\n",
        "    print(vocab['barber'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab 딕셔너리 빈도수가 높은순 정렬\n",
        "vocab_sorted = sorted(vocab.items(), key=lamda x:x[1], reverse=True)\n",
        "# 높은 빈도수일수록 낮은 정수를 부여 (정수는 1부터)\n",
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab_sorted:\n",
        "  if frequency > 1:\n",
        "    i += 1\n",
        "    word_to_index[word] = I\n",
        "  print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "-y5pY_qVu6VM",
        "outputId": "5d675c80-4236-43ab-e6d3-1862ae9680cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-313811db0e74>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    vocab_sorted = sorted(vocab.items(), key=lamda x:x[1], reverse=True)\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "# 인덱스가 5 초과인 단어 제거\n",
        "words_frequency = [word for word, index in word_to_index.items() if index > vocab_size]\n",
        "# 해당 단어에 대한 인덱스 정보를 삭제\n",
        "for w in words_frequency:\n",
        "  del word_to_index[w]\n",
        "  print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "PF0P7KU8zqIJ",
        "outputId": "b14e8556-6183-4fbc-ce1b-8026dcd16c6a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2b05718ebfb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 인덱스가 5 초과인 단어 제거\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwords_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# 해당 단어에 대한 인덱스 정보를 삭제\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_frequency\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'word_to_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index['OOV'] = len(word_to_index) + 1 # Out Of Vocabulary\n",
        "print(word_to_index)\n",
        "# 단어 집합에 있는 단어라면 해당 단어의 숫자를 없으면 'OOV'의 숫자를 반환\n",
        "encorded_sentences = []\n",
        "for sentence in preprocessed_sentences:\n",
        "  encorded_sentences = []\n",
        "  for word in sentence:\n",
        "    try:\n",
        "      encorded_sentences.append(word_to_index[word])\n",
        "    except KeyError:\n",
        "      encorded_sentences.append(word_to_index['OOV'])\n",
        "    encorded_sentences.append(encorded_sentences)\n",
        "  print(encorded_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "T98zbejF1-44",
        "outputId": "9785b8ce-223b-474a-c704-0abe670cc128"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6e0b8ea20106>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OOV'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# Out Of Vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 단어 집합에 있는 단어라면 해당 단어의 숫자를 없으면 'OOV'의 숫자를 반환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mencorded_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'word_to_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(preprocessed_sentences)\n",
        "\n",
        "all_word_list = sum(preprocessed_sentences, [])\n",
        "print(all_word_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjBWYkAz-Dpv",
        "outputId": "daf7e76e-bb3e-48ff-c305-b1edcf6025a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Counter(all_word_list)\n",
        "vocab\n",
        "vocab['barber']"
      ],
      "metadata": {
        "id": "DSJIu-mO-Y_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size)\n",
        "vocab\n",
        "# 높은 빈도수 순 인덱스 부여"
      ],
      "metadata": {
        "id": "7ACGycMsAUX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab:\n",
        "  i +=1\n",
        "  word_to_index[word] = i\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "id": "dN2UebtfAuRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "import numpy as np\n",
        "\n",
        "vocab = FreqDist(np.hstack(preprocessed_sentences))\n",
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size)\n",
        "print(vocab)"
      ],
      "metadata": {
        "id": "n3NL73RoB42O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {index[0] : index + 1 for index, word in enumerate(vocab)}\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "id": "M9HZyNT6DlL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)\n",
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "id": "umoRhS3RGgI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 1) # 상위 5개 단어만 사용\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)\n",
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "id": "j43ASQvvIu_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)\n",
        "print(tokenizer.word_index['OOV'])"
      ],
      "metadata": {
        "id": "tEXBWeDbJy9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YI2XykMbLOtU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}