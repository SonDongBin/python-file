{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "자연어처리_20220629.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPaMEqbbtgbS98X6uo9J4fT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonDongBin/python-file/blob/master/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC_20220629.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hUqF53ff26EI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"경마장에 있는 말이 뛰고 있다\n",
        "그의 말이 법이다\n",
        "가는 말이 고와야 오는 말이 곱다\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aU2-KbQY3DQa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : %d' % vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtEEZd0T3Gui",
        "outputId": "28617255-ab59-4c61-b28b-f039912e0892"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D--_hB13ZnK",
        "outputId": "6902040f-40bd-42ac-8ba6-66bf3f6e614b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list()\n",
        "for line in text.split('\\n'): # 줄바꿈 문자를 기준으로 문장 토큰화\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)"
      ],
      "metadata": {
        "id": "llnhxpmI3hjE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text.split('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf2IbS9E4Gls",
        "outputId": "518f04e1-6789-45c4-acbc-c42212055d30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['경마장에 있는 말이 뛰고 있다', '그의 말이 법이다', '가는 말이 고와야 오는 말이 곱다', '']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences(['경마장에 있는 말이 뛰고 있다'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUPKzW6p4LFR",
        "outputId": "56f7047b-7cc9-4288-ab72-de67550127e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3, 1, 4, 5]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srh2qCow4cZt",
        "outputId": "f0c998bd-793a-4a43-a4bd-8eadb72b2616"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYvGtWLp6KgC",
        "outputId": "7e63ead7-2b73-41c3-9d64-e88136001cc2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(len(i) for i in sequences)\n",
        "# [len(i) for i in sequences]\n",
        "\n",
        "# a = []\n",
        "# for i in sequences:\n",
        "#   a.append(len(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O8zbCQO6UJ9",
        "outputId": "aeb0a5ce-f9d1-4fcf-cd2c-3702381f4d0d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "text_g = pd.read_csv('ChatbotData.csv')\n",
        "text_g = text_g.A.copy()\n",
        "text_g.head()"
      ],
      "metadata": {
        "id": "yWlSao8W7vy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_g.shape\n",
        "pd.read_csv('ChatbotData.csv')['label'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "GHuRy2DkqX4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(text_g)[:10]\n",
        "tokenizer_g = Tokenizer()\n",
        "tokenizer_g.fit_on_texts(list(text_g))\n",
        "vocab_size_g = len(tokenizer_g.word_index) + 1\n",
        "print('단어 집합의 크기 : %d' % vocab_size_g)"
      ],
      "metadata": {
        "id": "4RMpjz9bqeAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_g = list()\n",
        "for line in text_g: # 줄바꿈 문자를 기준으로 문장 토큰화\n",
        "    encoded = tokenizer_g.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences_g.append(sequence)\n",
        "\n",
        "print('학습에 사용할 샘플의 개수: %d' % len(sequences_g))\n",
        "\n",
        "print(sequences_g)\n",
        "max_len_g = max(len(l) for l in sequences_g) \n",
        "print('샘플의 최대 길이 : {}'.format(max_len_g))"
      ],
      "metadata": {
        "id": "P1L8XCuCqfWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_g = pad_sequences(sequences_g, maxlen=max_len_g, padding='pre')\n",
        "print(sequences_g)"
      ],
      "metadata": {
        "id": "XXnkcGh7qgvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_g = np.array(sequences_g)\n",
        "X_chatbot_g = sequences_g[:,:-1]\n",
        "y_chatbot_g = sequences_g[:, -1]"
      ],
      "metadata": {
        "id": "QdWU_pkoqiPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X:', X_chatbot_g)\n",
        "print('y:', y_chatbot_g)"
      ],
      "metadata": {
        "id": "_zHDqVFPqjdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('전체 y의 개수:', len(y_chatbot_g))\n",
        "print('고유값 y의 개수:', np.unique(y_chatbot_g)[-1]+1)"
      ],
      "metadata": {
        "id": "zgNP0i1zqkwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_g = to_categorical(y_chatbot_g, num_classes=vocab_size_g)\n",
        "print(\"one_hot_vector y:\", y_one_g)"
      ],
      "metadata": {
        "id": "QyVrZUGkql9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model design\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, LSTM"
      ],
      "metadata": {
        "id": "cTsP8nwVqnaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 32\n",
        "hidden_units = 64\n",
        "\n",
        "model_g = Sequential()\n",
        "model_g.add(Embedding(vocab_size_g, embedding_dim))\n",
        "model_g.add(SimpleRNN(hidden_units))\n",
        "model_g.add(Dense(vocab_size_g, activation='softmax'))\n",
        "model_g.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_g.fit(X_chatbot_g, y_one_g, epochs=200, verbose=2)"
      ],
      "metadata": {
        "id": "Mpbz1EN7qoub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = currentword\n",
        "    sentence = ''\n",
        "\n",
        "    # n번 반복\n",
        "    for  in range(n):\n",
        "        # 현재 단어에 대한 정수 인코딩과 패딩\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
        "        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items(): \n",
        "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        current_word = current_word + ' '  + word\n",
        "\n",
        "        # 예측 단어를 문장에 저장\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "mmh8crGrqvKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model_g, tokenizer_g, '너는', 5))"
      ],
      "metadata": {
        "id": "JsAXHiaoqxU6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}