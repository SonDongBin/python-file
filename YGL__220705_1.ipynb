{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YGL_강의_220705.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPT7srB2wxTF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install zip"
      ],
      "metadata": {
        "id": "qHyGP0J_2a2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./kor-eng.zip"
      ],
      "metadata": {
        "id": "K1sCpAHx2fzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.manythings.org/anki/kor-eng.zip"
      ],
      "metadata": {
        "id": "l0KUAERY2PEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# http://www.manythings.org/anki/kor-eng.zip\n",
        "## 한국어/영어 자료 다운로드 후 번역 학습 및 예측해 보기\n",
        "## word embedding도 구현해 보기"
      ],
      "metadata": {
        "id": "PdZVdSx-1yoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines = pd.read_csv('./kor.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
        "lines"
      ],
      "metadata": {
        "id": "awEjUPrPz4hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in lines.src.iloc[-5:]:\n",
        "  print(i)\n",
        "  print('문장의 길이: ', len(i))"
      ],
      "metadata": {
        "id": "S0JrtAt70UtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines['length_src'] = lines.src.apply(lambda x:len(x))\n",
        "lines['length_tar'] = lines.tar.apply(lambda x:len(x))"
      ],
      "metadata": {
        "id": "-ulHowVF1DLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines"
      ],
      "metadata": {
        "id": "GJkXRDel1ygm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('src 평균: %.1f' %(lines.length_src.mean()))\n",
        "print('src 중앙값: ', lines.length_src.median())\n",
        "print('src 최대값: ', lines.length_src.max())\n",
        "lines.length_src.plot(kind='hist', bins=100)"
      ],
      "metadata": {
        "id": "u4bdk4pQ1zyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('taret 평균: %.1f' %(lines.length_tar.mean()))\n",
        "print('taret 중앙값: ', lines.length_tar.median())\n",
        "print('taret 최대값: ', lines.length_tar.max())\n",
        "lines.length_tar.plot(kind='hist', bins=100)"
      ],
      "metadata": {
        "id": "uz4V8v0n2Bkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_30 = lines.loc[lines.length_src <= 15]\n",
        "lines_30 = lines_30.reset_index()\n",
        "lines_30.drop(['index','lic', 'length_src', 'length_tar'], axis=1, inplace=True)\n",
        "lines_30['tar'] = lines_30.tar.apply(lambda x: '\\t ' + x + ' \\n')"
      ],
      "metadata": {
        "id": "BLIejZbK3SKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_30"
      ],
      "metadata": {
        "id": "6GfmEwcyjNWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_30.isna().sum()"
      ],
      "metadata": {
        "id": "cbEeaDx1kZlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = set()\n",
        "for line in lines_30.src:\n",
        "  for char in line:\n",
        "    src_vocab.add(char)\n",
        "\n",
        "tar_vocab = set()\n",
        "for line in lines_30.tar:\n",
        "  for char in line:\n",
        "    tar_vocab.add(char)"
      ],
      "metadata": {
        "id": "VI5wP5nQ-Efh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('src_vocab:', '\\n', src_vocab)\n",
        "#print('src_vocab length: ', len(src_vocab), '\\n')\n",
        "print('tar_vocab:', '\\n', tar_vocab)\n",
        "#print('tar_vocab length: ', len(tar_vocab))"
      ],
      "metadata": {
        "id": "qyNmz1E4-wZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(src_vocab) + 1\n",
        "tar_vocab_size = len(tar_vocab) + 1\n",
        "print('src_vocab_size: ', src_vocab_size)\n",
        "print('tar_vocab_size: ', tar_vocab_size)"
      ],
      "metadata": {
        "id": "iXkqinp5_Yug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = sorted(src_vocab)\n",
        "tar_vocab = sorted(tar_vocab)"
      ],
      "metadata": {
        "id": "0CxF6b1JAWdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_vocab[50:75])\n",
        "print(tar_vocab[50:75])"
      ],
      "metadata": {
        "id": "8lodJ9_hA0Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_vocab[:2])\n",
        "print(tar_vocab[:2])"
      ],
      "metadata": {
        "id": "yNF_uj-uBCpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dict([('a', 'b')])\n",
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])"
      ],
      "metadata": {
        "id": "sEAyW8ydBgep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_to_index)\n",
        "print(tar_to_index)"
      ],
      "metadata": {
        "id": "Pz5jJ-bbBr2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_to_index['a']"
      ],
      "metadata": {
        "id": "Z7vml-bnHzVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = []\n",
        "\n",
        "for line in lines_30.src:\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    encoded_line.append(src_to_index[char])\n",
        "  encoder_input.append(encoded_line)"
      ],
      "metadata": {
        "id": "p_qUtoVmCsmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('src 문장 인코딩: ', encoder_input[:5])\n",
        "print('src 문장 원본  : ', '\\n', lines_30.src[:5])"
      ],
      "metadata": {
        "id": "rMGSLw34HVH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('src 문장 인코딩 last_one: ', encoder_input[-1])"
      ],
      "metadata": {
        "id": "rpRUEvf7IYhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input = []\n",
        "\n",
        "for line in lines_30.tar:\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    encoded_line.append(tar_to_index[char])\n",
        "  decoder_input.append(encoded_line)"
      ],
      "metadata": {
        "id": "yai3tpaQI0ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('src 문장 인코딩: ', decoder_input[:5])\n",
        "print('src 문장 원본  : ', '\\n', lines_30.tar[:5])"
      ],
      "metadata": {
        "id": "9ix5UNlFJqiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target = []\n",
        "\n",
        "for line in lines_30.tar:\n",
        "  timestep = 0\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    if timestep > 0:\n",
        "      encoded_line.append(tar_to_index[char])\n",
        "    timestep += 1\n",
        "  decoder_target.append(encoded_line)"
      ],
      "metadata": {
        "id": "n-ZrAaWZJvru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_input[:5])\n",
        "print(decoder_input[:5])\n",
        "print(decoder_target[:5])"
      ],
      "metadata": {
        "id": "iWEznouYL-yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_src_len = max([len(line) for line in lines_30.src])\n",
        "max_tar_len = max([len(line) for line in lines_30.tar])\n",
        "print('max_src_len: ', max_src_len)\n",
        "print('max_tar_len: ', max_tar_len)"
      ],
      "metadata": {
        "id": "bmGCtSiIMp-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
      ],
      "metadata": {
        "id": "l3HhARIjNliG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_input[0])\n",
        "print(len(encoder_input[0]))\n",
        "print(decoder_input[0])\n",
        "print(len(decoder_input[0]))\n",
        "print(decoder_target[0])\n",
        "print(len(decoder_target[0]))"
      ],
      "metadata": {
        "id": "azxoIUKtN080"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "metadata": {
        "id": "MFAnfBK1OPi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('encoder input dim: ', encoder_input.shape)\n",
        "print('number of samples: ', lines_30.shape[0])\n",
        "print('max_src_len: ', max_src_len)\n",
        "print('src_vocab_size: ', src_vocab_size)\n",
        "print('-'*40)\n",
        "print('decoder input dim: ', decoder_input.shape)\n",
        "print('number of samples: ', lines_30.shape[0])\n",
        "print('max_tar_len: ', max_tar_len)\n",
        "print('tar_vocab_size: ', tar_vocab_size)\n",
        "print('-'*40)\n",
        "print('decoder target dim: ', decoder_target.shape)"
      ],
      "metadata": {
        "id": "04_6SiBGPCql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, SimpleRNN, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "yt6q9ccHQ6ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_test = Input(82)\n",
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(256, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_state=True, return_sequences=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target,\n",
        "          batch_size=64, epochs=40, validation_split=0.2)"
      ],
      "metadata": {
        "id": "hCmxZlnCVPFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target,\n",
        "          batch_size=64, epochs=40, validation_split=0.2)"
      ],
      "metadata": {
        "id": "o-Bn83cg5mgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_decoder_trainig(state_dim, batch_size, epochs):\n",
        "  encoder_input_test = Input(82)\n",
        "  encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "  encoder_lstm = LSTM(state_dim, return_state=True)\n",
        "  encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "  encoder_states = [state_h, state_c]\n",
        "\n",
        "  decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "  decoder_lstm = LSTM(units=state_dim, return_state=True, return_sequences=True)\n",
        "  decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "  decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "  decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "  model.fit(x=[encoder_input, decoder_input], y=decoder_target,\n",
        "            batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "metadata": {
        "id": "cZbGJEubnzBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_decoder_trainig(512, 64, 40*3)"
      ],
      "metadata": {
        "id": "1TCYV3einzEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(inputs=encoder_inputs , outputs=encoder_states)"
      ],
      "metadata": {
        "id": "A9wUzADSG1bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_state_input = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_input)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_state_input,\n",
        "                      outputs=[decoder_outputs, state_h, state_c])"
      ],
      "metadata": {
        "id": "q8pNNJslHqKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ],
      "metadata": {
        "id": "RAHP7ji6M0pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_value = encoder_model.predict(encoder_input[:1])"
      ],
      "metadata": {
        "id": "5Y1CkydmOWxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('encoder_states_value')\n",
        "print('*'*75)\n",
        "print('len(states_value): ', len(states_value))\n",
        "print('-'*70)\n",
        "print('h: ', states_value[0])\n",
        "print('h dim: ', states_value[0].shape)\n",
        "print('-'*70)\n",
        "print('c: ', states_value[1])\n",
        "print('c dim: ', states_value[1].shape)\n",
        "print('-'*70)"
      ],
      "metadata": {
        "id": "IX8hhjSJPYSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <sos> 입력값 생성\n",
        "print(np.zeros((2,2)))\n",
        "print(tar_vocab_size)\n",
        "print(np.zeros((1,1,tar_vocab_size)))\n",
        "target_seq = np.zeros((1,1,tar_vocab_size))\n",
        "print(target_seq.shape)"
      ],
      "metadata": {
        "id": "81welXKnO_LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tar_to_index['\\t']"
      ],
      "metadata": {
        "id": "wIhyWjNaRfBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_seq[0,0,1] = 1"
      ],
      "metadata": {
        "id": "vzUPCV3pSYvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(target_seq)\n",
        "print(target_seq.shape)"
      ],
      "metadata": {
        "id": "RYiyn91TSwJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('1 target_seq (<sos>, decoder model 예측 시 입력)')\n",
        "print('*' * 75)\n",
        "print('target_seq:', '\\n', target_seq)\n",
        "print('target_seq[0][0]: ', target_seq[0][0])\n",
        "print('len(target_seq[0][0]): ', len(target_seq[0][0]))\n",
        "print('target_seq.shape: ', target_seq.shape)\n",
        "print('*' * 75)\n",
        "print('2 states_value (인코더 모델 히든, 셀 상태 출력을 예측 시 입력)')\n",
        "print('*' * 75)\n",
        "print('states_value:', '\\n', states_value)\n",
        "print('len(states_value):', len(states_value))\n",
        "print('*' * 75)\n",
        "print('2.1 히든 상태값 (state_value[0])')\n",
        "print('-' * 70)\n",
        "print(states_value[0])\n",
        "print('states_value[0].shape:', states_value[0].shape)\n",
        "print('-' * 70, '\\n')\n",
        "\n",
        "print('2.2 셀 상태값 (state_value[1])')\n",
        "print('-' * 70)\n",
        "print(states_value[1])\n",
        "print('states_value[1].shape:', states_value[1].shape)\n",
        "print('-' * 70, '\\n')"
      ],
      "metadata": {
        "id": "PPL2JqarU8kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_input = [target_seq] + states_value\n",
        "print(pre_input)\n",
        "print(len(pre_input))\n",
        "print('sos: ', pre_input[0])\n",
        "print('sos dim: ', pre_input[0].shape)\n",
        "print('h: ', pre_input[1])\n",
        "print('h dim: ', pre_input[1].shape)\n",
        "print('c: ', pre_input[2])\n",
        "print('c dim: ', pre_input[2].shape)"
      ],
      "metadata": {
        "id": "AKiIdabSVrlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_tokens, h, c = decoder_model.predict(pre_input)"
      ],
      "metadata": {
        "id": "zAM18K8_VuHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('output_tokens:', '\\n', output_tokens)\n",
        "print('output_tokens.shape: ', output_tokens.shape)\n",
        "print('sum of output_tokens: ', np.sum(output_tokens))\n",
        "print('max value index: ', np.argmax(output_tokens))\n",
        "sampled_token_index = np.argmax(output_tokens)\n",
        "print('index_to_tar: ', index_to_tar)\n",
        "print('character: ', index_to_tar[sampled_token_index])\n",
        "sampled_char = index_to_tar[sampled_token_index]"
      ],
      "metadata": {
        "id": "F6Fvqk74Yaip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "  target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "  target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  while not stop_condition:\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "    if (sampled_char == '\\n' or\n",
        "        len(decoded_sentence) > max_tar_len):\n",
        "        stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "d_UJzE1VaHiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lines.iloc[10])\n",
        "print(decode_sequence(encoder_input[10:11]))"
      ],
      "metadata": {
        "id": "t0GRGPMjca7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 601, 30):\n",
        "  print('입력문장:', lines_30.src[i])\n",
        "  print('출력문장:', lines_30.tar[i][2:-1])\n",
        "  print('예측문장:', decode_sequence(encoder_input[i:i+1])[1:-1])\n",
        "  print('-'*30)"
      ],
      "metadata": {
        "id": "2IWz5KWPdoB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-cVh6gxJfAYL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}